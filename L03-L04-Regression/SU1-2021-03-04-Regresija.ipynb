{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sveučilište u Zagrebu  \n",
    "Fakultet elektrotehnike i računarstva  \n",
    "  \n",
    "## Strojno učenje 1 2021/2022  \n",
    "http://www.fer.unizg.hr/predmet/struce1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------------\n",
    "\n",
    "### Regresija\n",
    "\n",
    "*Verzija: 1.0\n",
    "Zadnji put ažurirano: 1. 10. 2021.*\n",
    "\n",
    "(c) 2015-2021 Jan Šnajder, Domagoj Alagić \n",
    "\n",
    "Rok za predaju: **24. listopada 2021. u 23:59h**\n",
    "\n",
    "------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upute\n",
    "\n",
    "Prva laboratorijska vježba sastoji se od četiri zadatka, te tri dodatna zadatka koji se **ne boduju**. U nastavku slijedite upute navedene u ćelijama s tekstom. Rješavanje vježbe svodi se na **dopunjavanje ove bilježnice**: umetanja ćelije ili više njih **ispod** teksta zadatka, pisanja odgovarajućeg kôda te evaluiranja ćelija. \n",
    "\n",
    "Osigurajte da u potpunosti **razumijete** kôd koji ste napisali. Kod predaje vježbe, morate biti u stanju na zahtjev asistenta (ili demonstratora) preinačiti i ponovno evaluirati Vaš kôd. Nadalje, morate razumjeti teorijske osnove onoga što radite, u okvirima onoga što smo obradili na predavanju. Ispod nekih zadataka možete naći i pitanja koja služe kao smjernice za bolje razumijevanje gradiva (**nemojte pisati** odgovore na pitanja u bilježnicu). Stoga se nemojte ograničiti samo na to da riješite zadatak, nego slobodno eksperimentirajte. To upravo i jest svrha ovih vježbi.\n",
    "\n",
    "Vježbe trebate raditi **samostalno**. Možete se konzultirati s drugima o načelnom načinu rješavanja, ali u konačnici morate sami odraditi vježbu. U protivnome vježba nema smisla."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "# Učitaj osnovne biblioteke...\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import matplotlib.pyplot as plt\n",
    "%pylab inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Jednostavna regresija"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zadan je skup primjera $\\mathcal{D}=\\{(x^{(i)},y^{(i)})\\}_{i=1}^4 = \\{(0,4),(1,1),(2,2),(4,5)\\}$. Primjere predstavite matricom $\\mathbf{X}$ dimenzija $N\\times n$ (u ovom slučaju $4\\times 1$) i vektorom oznaka $\\textbf{y}$, dimenzija $N\\times 1$ (u ovom slučaju $4\\times 1$), na sljedeći način:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X:\n",
      "[[0]\n",
      " [1]\n",
      " [2]\n",
      " [4]]\n",
      "\n",
      "y:\n",
      "[4 1 2 5]\n"
     ]
    }
   ],
   "source": [
    "X = np.array([[0],[1],[2],[4]])\n",
    "y = np.array([4,1,2,5])\n",
    "\n",
    "print(f\"X:\\n{X}\\n\")\n",
    "print(f\"y:\\n{y}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (a)\n",
    "\n",
    "Proučite funkciju [`PolynomialFeatures`](http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.PolynomialFeatures.html) iz biblioteke `sklearn` i upotrijebite je za generiranje matrice dizajna $\\mathbf{\\Phi}$ koja ne koristi preslikavanje u prostor više dimenzije (samo će svakom primjeru biti dodane *dummy* jedinice; $m=n+1$).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "phi:\n",
      "[[1. 0.]\n",
      " [1. 1.]\n",
      " [1. 2.]\n",
      " [1. 4.]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "poly = PolynomialFeatures(degree=1, interaction_only=False, include_bias=True)\n",
    "phi = poly.fit_transform(X)\n",
    "print(f\"phi:\\n{phi}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Upoznajte se s modulom [`linalg`](http://docs.scipy.org/doc/numpy/reference/routines.linalg.html). Izračunajte težine $\\mathbf{w}$ modela linearne regresije kao $\\mathbf{w}=(\\mathbf{\\Phi}^\\intercal\\mathbf{\\Phi})^{-1}\\mathbf{\\Phi}^\\intercal\\mathbf{y}$. Zatim se uvjerite da isti rezultat možete dobiti izračunom pseudoinverza $\\mathbf{\\Phi}^+$ matrice dizajna, tj. $\\mathbf{w}=\\mathbf{\\Phi}^+\\mathbf{y}$, korištenjem funkcije [`pinv`](http://docs.scipy.org/doc/numpy/reference/generated/numpy.linalg.pinv.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "phi_transposed:\n",
      "[[1. 1. 1. 1.]\n",
      " [0. 1. 2. 4.]]\n",
      "\n",
      "first_product:\n",
      "[[ 4.  7.]\n",
      " [ 7. 21.]]\n",
      "\n",
      "inversed:\n",
      "[[ 0.6        -0.2       ]\n",
      " [-0.2         0.11428571]]\n",
      "\n",
      "w 1:\n",
      "[2.2        0.45714286]\n",
      "\n",
      "pseudo-inverse:\n",
      "[[ 0.6         0.4         0.2        -0.2       ]\n",
      " [-0.2        -0.08571429  0.02857143  0.25714286]]\n",
      "\n",
      "w 2:\n",
      "[2.2        0.45714286]\n"
     ]
    }
   ],
   "source": [
    "from numpy import linalg\n",
    "\n",
    "# first w\n",
    "phi_transposed = np.transpose(phi) #matrix.transpose(phi)\n",
    "print(f\"phi_transposed:\\n{phi_transposed}\\n\")\n",
    "first_product = np.dot(phi_transposed, phi)\n",
    "print(f\"first_product:\\n{first_product}\\n\")\n",
    "inversed = linalg.inv(first_product)\n",
    "print(f\"inversed:\\n{inversed}\\n\")\n",
    "\n",
    "w_1 = np.dot(np.dot(inversed, phi_transposed), y)\n",
    "print(f\"w 1:\\n{w_1}\\n\")\n",
    "\n",
    "# second w\n",
    "pinv = linalg.pinv(phi)\n",
    "print(f\"pseudo-inverse:\\n{pinv}\\n\")\n",
    "\n",
    "w_2 = np.dot(pinv, y)\n",
    "print(f\"w 2:\\n{w_2}\")\n",
    "\n",
    "assert(np.allclose(w_1, w_2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Radi jasnoće, u nastavku je vektor $\\mathbf{x}$ s dodanom *dummy* jedinicom $x_0=1$ označen kao $\\tilde{\\mathbf{x}}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prikažite primjere iz $\\mathcal{D}$ i funkciju $h(\\tilde{\\mathbf{x}})=\\mathbf{w}^\\intercal\\tilde{\\mathbf{x}}$. Izračunajte pogrešku učenja prema izrazu $E(h|\\mathcal{D})=\\frac{1}{2}\\sum_{i=1}^N(\\tilde{\\mathbf{y}}^{(i)} - h(\\tilde{\\mathbf{x}}^{(i)}))^2$. Možete koristiti funkciju srednje kvadratne pogreške [`mean_squared_error`]( http://scikit-learn.org/stable/modules/generated/sklearn.metrics.mean_squared_error.html) iz modula [`sklearn.metrics`](http://scikit-learn.org/stable/modules/classes.html#module-sklearn.metrics).\n",
    "\n",
    "**Q:** Gore definirana funkcija pogreške $E(h|\\mathcal{D})$ i funkcija srednje kvadratne pogreške nisu posve identične. U čemu je razlika? Koja je \"realnija\"?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w: [2.2        0.45714286]\n",
      "w trans: [[2.2       ]\n",
      " [0.45714286]]\n",
      "x: [[1. 0.]\n",
      " [1. 1.]\n",
      " [1. 2.]\n",
      " [1. 4.]]\n",
      "(2,)\n",
      "[[1. 0.]\n",
      " [1. 1.]\n",
      " [1. 2.]\n",
      " [1. 4.]]\n",
      "h:\n",
      "[2.2        2.65714286 3.11428571 4.02857143]\n",
      "\n",
      "E: 2.042857142857143\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "w = w_2\n",
    "x = phi\n",
    "\n",
    "# TODO FUCK\n",
    "w_trans = np.transpose(np.asmatrix(w)) #np.asarray(np.transpose(w))\n",
    "print(f\"w: {w}\")\n",
    "print(f\"w trans: {w_trans}\")\n",
    "print(f\"x: {x}\")\n",
    "\n",
    "print(w.shape)\n",
    "print(x)\n",
    "#2,1 X 4,2 X 1,2\n",
    "#np.dot(np.asarray(w), x)\n",
    "# TODO FUCK\n",
    "\n",
    "h = np.dot(x, w)\n",
    "print(f\"h:\\n{h}\\n\")\n",
    "\n",
    "E = mean_squared_error(y, h)\n",
    "print(f\"E: {E}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uvjerite se da za primjere iz $\\mathcal{D}$ težine $\\mathbf{w}$ ne možemo naći rješavanjem sustava $\\mathbf{w}=\\mathbf{\\Phi}^{-1}\\mathbf{y}$, već da nam doista treba pseudoinverz.\n",
    "\n",
    "**Q:** Zašto je to slučaj? Bi li se problem mogao riješiti preslikavanjem primjera u višu dimenziju? Ako da, bi li to uvijek funkcioniralo, neovisno o skupu primjera $\\mathcal{D}$? Pokažite na primjeru."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "ename": "LinAlgError",
     "evalue": "Last 2 dimensions of the array must be square",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mLinAlgError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-160-cf99e54a1b1f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mphi_inv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mphi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36minv\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/numpy/linalg/linalg.py\u001b[0m in \u001b[0;36minv\u001b[0;34m(a)\u001b[0m\n\u001b[1;32m    538\u001b[0m     \u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwrap\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_makearray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    539\u001b[0m     \u001b[0m_assert_stacked_2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 540\u001b[0;31m     \u001b[0m_assert_stacked_square\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    541\u001b[0m     \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult_t\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_commonType\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    542\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/numpy/linalg/linalg.py\u001b[0m in \u001b[0;36m_assert_stacked_square\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    201\u001b[0m         \u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mm\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 203\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mLinAlgError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Last 2 dimensions of the array must be square'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    204\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_assert_finite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mLinAlgError\u001b[0m: Last 2 dimensions of the array must be square"
     ]
    }
   ],
   "source": [
    "phi_inv = linalg.inv(phi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (e) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Proučite klasu [`LinearRegression`](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html) iz modula [`sklearn.linear_model`](http://scikit-learn.org/stable/modules/classes.html#module-sklearn.linear_model). Provjerite jesu li težine koje izračunava ta funkcija (dostupne pomoću atributa `coef_` i `intercept_`) jednake onima koje ste izračunali gore. Ako nisu, prilagodite kôd tako da jest.\n",
    "\n",
    "**NB:** Obratite pozornost na to kako klase [`LinearRegression`](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html) i [`PolynomialFeatures`](http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.PolynomialFeatures.html) koriste pomak i osigurajte da ga ne dodajete više puta.\n",
    "\n",
    "Izračunajte predikcije modela (metoda `predict`) i uvjerite se da je pogreška učenja identična onoj koju ste ranije izračunali."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w:\n",
      "[2.2, 0.45714285714285713]\n",
      "\n",
      "h: \n",
      "[2.2        2.65714286 3.11428571 4.02857143]\n",
      "\n",
      "E: 2.042857142857143\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "reg = LinearRegression().fit(phi, y)\n",
    "w1 = reg.coef_[1]\n",
    "w0 = reg.intercept_\n",
    "w = [w0, w1]\n",
    "print(f\"w:\\n{w}\\n\")\n",
    "\n",
    "h2 = reg.predict(phi)\n",
    "print(f\"h: \\n{h2}\\n\")\n",
    "assert(np.allclose(h, h2))\n",
    "\n",
    "E2 = mean_squared_error(y, h2)\n",
    "print(f\"E: {E2}\")\n",
    "assert(E == E2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Polinomijalna regresija i utjecaj šuma"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (a)\n",
    "\n",
    "Razmotrimo sada regresiju na većem broju primjera. Definirajte funkciju `make_labels(X, f, noise=0)` koja uzima matricu neoznačenih primjera $\\mathbf{X}_{N\\times n}$ te generira vektor njihovih oznaka $\\mathbf{y}_{N\\times 1}$. Oznake se generiraju kao $y^{(i)} = f(x^{(i)})+\\mathcal{N}(0,\\sigma^2)$, gdje je $f:\\mathbb{R}^n\\to\\mathbb{R}$ stvarna funkcija koja je generirala podatke (koja nam je u stvarnosti nepoznata), a $\\sigma$ je standardna devijacija Gaussovog šuma, definirana parametrom `noise`. Za generiranje šuma možete koristiti funkciju [`numpy.random.normal`](https://numpy.org/doc/stable/reference/random/generated/numpy.random.normal.html). \n",
    "\n",
    "Generirajte skup za učenje od $N=50$ primjera uniformno distribuiranih u intervalu $[-5,5]$ pomoću funkcije $f(x) = 5 + x -2 x^2 -5 x^3$ uz šum  $\\sigma=200$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.random import normal\n",
    "\n",
    "def make_labels(X, f, noise=0):\n",
    "    y = f(X) + normal(0, noise, len(X))\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_instances(x1, x2, N) :\n",
    "    return np.array([np.array(x) for x in np.linspace(x1,x2,N)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(x):\n",
    "    y = 5 + x - 2 * x**2 - 5 * x**3\n",
    "    return y\n",
    "\n",
    "N = 50\n",
    "sigma_noise = 200\n",
    "x1 = -5\n",
    "x2 = 5\n",
    "X = make_instances(x1, x2, N)\n",
    "y = make_labels(X, f, sigma_noise)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prikažite taj skup funkcijom [`scatter`](http://matplotlib.org/api/pyplot_api.html#matplotlib.pyplot.scatter)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7f883f8a0730>"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trenirajte model polinomijalne regresije stupnja $d=3$. Na istom grafikonu prikažite naučeni model $h(\\mathbf{x})=\\mathbf{w}^\\intercal\\tilde{\\mathbf{x}}$ i primjere za učenje. Izračunajte pogrešku učenja modela."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E: 31761.215735490387\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f883f887e50>]"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "poly = PolynomialFeatures(degree=3, interaction_only=False, include_bias=True)\n",
    "phi = poly.fit_transform(X.reshape(-1, 1))\n",
    "\n",
    "# w\n",
    "pinv = linalg.pinv(phi)\n",
    "w = np.dot(pinv, y)\n",
    "\n",
    "# h\n",
    "x = phi\n",
    "h = np.dot(x, w)  # TODO WTF\n",
    "\n",
    "# E\n",
    "E = mean_squared_error(y, h)\n",
    "print(f\"E: {E}\")\n",
    "\n",
    "# graph\n",
    "plt.scatter(X, y) # primjeri za ucenje\n",
    "plt.plot(X, h) # nauceni model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Odabir modela"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (a)\n",
    "\n",
    "Na skupu podataka iz zadatka 2 trenirajte pet modela linearne regresije $\\mathcal{H}_d$ različite složenosti, gdje je $d$ stupanj polinoma, $d\\in\\{1,3,5,10,20\\}$. Prikažite na istome grafikonu skup za učenje i funkcije $h_d(\\mathbf{x})$ za svih pet modela (preporučujemo koristiti `plot` unutar `for` petlje). Izračunajte pogrešku učenja svakog od modela.\n",
    "\n",
    "**Q:** Koji model ima najmanju pogrešku učenja i zašto?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Vaš kôd ovdje"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Razdvojite skup primjera iz zadatka 2 pomoću funkcije [`model_selection.train_test_split`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html) na skup za učenja i skup za ispitivanje u omjeru 1:1. Prikažite na jednom grafikonu pogrešku učenja i ispitnu pogrešku za modele polinomijalne regresije $\\mathcal{H}_d$, sa stupnjem polinoma $d$ u rasponu $d\\in [1,2,\\ldots,20]$. Budući da kvadratna pogreška brzo raste za veće stupnjeve polinoma, umjesto da iscrtate izravno iznose pogrešaka, iscrtajte njihove logaritme.\n",
    "\n",
    "**NB:** Podjela na skupa za učenje i skup za ispitivanje mora za svih pet modela biti identična.\n",
    "\n",
    "**Q:** Je li rezultat u skladu s očekivanjima? Koji biste model odabrali i zašto?\n",
    "\n",
    "**Q:** Pokrenite iscrtavanje više puta. U čemu je problem? Bi li problem bio jednako izražen kad bismo imali više primjera? Zašto?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# Vaš kôd ovdje"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Točnost modela ovisi o (1) njegovoj složenosti (stupanj $d$ polinoma), (2) broju primjera $N$, i (3) količini šuma. Kako biste to analizirali, nacrtajte grafikone pogrešaka kao u 3b, ali za različit $N\\in$ (trećina, dvije trećine, sve) i količine šuma $\\sigma\\in\\{100,200,500\\}$ (ukupno 9 grafikona). Upotrijebite funkciju [`subplots`](http://matplotlib.org/examples/pylab_examples/subplots_demo.html) kako biste pregledno posložili grafikone u tablicu $3\\times 3$. Podatci se generiraju na isti način kao u zadatku 2.\n",
    "\n",
    "**NB:** Pobrinite se da svi grafikoni budu generirani nad usporedivim skupovima podataka, na sljedeći način. Generirajte najprije svih 1000 primjera, podijelite ih na skupove za učenje i skupove za ispitivanje (dva skupa od po 500 primjera). Zatim i od skupa za učenje i od skupa za ispitivanje načinite tri različite verzije, svaka s drugačijom količinom šuma (ukupno 2x3=6 verzija podataka). Kako bi simulirali veličinu skupa podataka, od tih dobivenih 6 skupova podataka uzorkujte trećinu, dvije trećine i sve podatke. Time ste dobili 18 skupova podataka -- skup za učenje i za testiranje za svaki od devet grafova."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Vaš kôd ovdje"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Q:*** Jesu li rezultati očekivani? Obrazložite."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Regularizirana regresija"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (a)\n",
    "\n",
    "U gornjim eksperimentima nismo koristili **regularizaciju**. Vratimo se najprije na primjer iz zadatka 1. Na primjerima iz tog zadatka izračunajte težine $\\mathbf{w}$ za polinomijalni regresijski model stupnja $d=3$ uz L2-regularizaciju (tzv. *ridge regression*), prema izrazu $\\mathbf{w}=(\\mathbf{\\Phi}^\\intercal\\mathbf{\\Phi}+\\lambda\\mathbf{I})^{-1}\\mathbf{\\Phi}^\\intercal\\mathbf{y}$. Napravite izračun težina za regularizacijske faktore $\\lambda=0$, $\\lambda=1$ i $\\lambda=10$ te usporedite dobivene težine.\n",
    "\n",
    "**Q:** Kojih je dimenzija matrica koju treba invertirati?\n",
    "\n",
    "**Q:** Po čemu se razlikuju dobivene težine i je li ta razlika očekivana? Obrazložite."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Vaš kôd ovdje"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Proučite klasu [`Ridge`](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Ridge.html#sklearn.linear_model.Ridge) iz modula [`sklearn.linear_model`](http://scikit-learn.org/stable/modules/classes.html#module-sklearn.linear_model), koja implementira L2-regularizirani regresijski model. Parametar $\\alpha$ odgovara parametru $\\lambda$. Primijenite model na istim primjerima kao u prethodnom zadatku i ispišite težine $\\mathbf{w}$ (atributi `coef_` i `intercept_`). Ponovno, pripazite na pomak.\n",
    "\n",
    "**Q:** Jesu li težine identične onima iz zadatka 4a? Ako nisu, objasnite zašto je to tako i kako biste to popravili."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "# Vaš kôd ovdje"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (c)\n",
    "\n",
    "Vratimo se na slučaj $N=50$ slučajno generiranih primjera iz zadatka 2. Trenirajte modele polinomijalne regresije $\\mathcal{H}_{\\lambda,d}$ za $\\lambda\\in\\{0,100\\}$ i $d\\in\\{2,10\\}$ (ukupno četiri modela). Skicirajte pripadne funkcije $h(\\mathbf{x})$ i primjere (na jednom grafikonu; preporučujemo koristiti `plot` unutar `for` petlje).\n",
    "\n",
    "**Q:** Jesu li rezultati očekivani? Obrazložite."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Vaš kôd ovdje"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (d)\n",
    "\n",
    "Kao u zadataku 3b, razdvojite primjere na skup za učenje i skup za ispitivanje u omjeru 1:1. Prikažite krivulje logaritama pogreške učenja i ispitne pogreške u ovisnosti za model $\\mathcal{H}_{d=10,\\lambda}$, podešavajući faktor regularizacije $\\lambda$ u rasponu $\\lambda\\in\\{0,1,\\dots,50\\}$.\n",
    "\n",
    "**Q:** Kojoj strani na grafikonu odgovara područje prenaučenosti, a kojoj podnaučenosti? Zašto?\n",
    "\n",
    "**Q:** Koju biste vrijednosti za $\\lambda$ izabrali na temelju ovih grafikona i zašto?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Vaš kôd ovdje"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dodatni zadatci\n",
    "\n",
    "Zadatci u nastavku (označeni zvjezdicom) nisu dio obaveznog dijela laboratorijske vježbe, niti nose bonus bodove. Dakle, nije ih potrebno riješiti kako biste ostvarili 100% bodova na ovoj laboratorijskoj vježbi. Međutim, preporučamo vam da ih pokušate riješiti i na terminu predaje prodiskutirate svoja rješenja s asistentima."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *5. L1-regularizacija i L2-regularizacija"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Svrha regularizacije jest potiskivanje težina modela $\\mathbf{w}$ prema nuli, kako bi model bio što jednostavniji. Složenost modela može se okarakterizirati normom pripadnog vektora težina $\\mathbf{w}$, i to tipično L2-normom ili L1-normom. Za jednom trenirani model možemo izračunati i broj ne-nul značajki, ili L0-normu, pomoću sljedeće funkcije koja prima vektor težina $\\mathbf{w}$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def nonzeroes(coef, tol=1e-6): \n",
    "    return len(coef) - len(coef[np.isclose(0, coef, atol=tol)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (a)\n",
    "\n",
    "Za ovaj zadatak upotrijebite skup za učenje i skup za testiranje iz zadatka 3b. Trenirajte modele **L2-regularizirane** polinomijalne regresije stupnja $d=5$, mijenjajući hiperparametar $\\lambda$ u rasponu $\\{1,2,\\dots,100\\}$. Za svaki od treniranih modela izračunajte L{0,1,2}-norme vektora težina $\\mathbf{w}$ te ih prikažite kao funkciju od $\\lambda$. Pripazite što točno šaljete u funkciju za izračun normi.\n",
    "\n",
    "**Q:** Objasnite oblik obiju krivulja. Hoće li krivulja za $\\|\\mathbf{w}\\|_2$ doseći nulu? Zašto? Je li to problem? Zašto?\n",
    "\n",
    "**Q:** Za $\\lambda=100$, koliki je postotak težina modela jednak nuli, odnosno koliko je model rijedak?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "# Vaš kôd ovdje"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Glavna prednost L1-regularizirane regresije (ili *LASSO regression*) nad L2-regulariziranom regresijom jest u tome što L1-regularizirana regresija rezultira **rijetkim modelima** (engl. *sparse models*), odnosno modelima kod kojih su mnoge težine pritegnute na nulu. Pokažite da je to doista tako, ponovivši gornji eksperiment s **L1-regulariziranom** regresijom, implementiranom u klasi  [`Lasso`](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Lasso.html) u modulu [`sklearn.linear_model`](http://scikit-learn.org/stable/modules/classes.html#module-sklearn.linear_model)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "# Vaš kôd ovdje"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *6. Značajke različitih skala"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Često se u praksi možemo susreti sa podatcima u kojima sve značajke nisu jednakih magnituda. Primjer jednog takvog skupa je regresijski skup podataka `grades` u kojem se predviđa prosjek ocjena studenta na studiju (1--5) na temelju dvije značajke: bodova na prijamnom ispitu (1--3000) i prosjeka ocjena u srednjoj školi. Prosjek ocjena na studiju izračunat je kao težinska suma ove dvije značajke uz dodani šum.\n",
    "\n",
    "Koristite sljedeći kôd kako biste generirali ovaj skup podataka."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_data_points = 500\n",
    "np.random.seed(69)\n",
    "\n",
    "# Generiraj podatke o bodovima na prijamnom ispitu koristeći normalnu razdiobu i ograniči ih na interval [1, 3000].\n",
    "exam_score = np.random.normal(loc=1500.0, scale = 500.0, size = n_data_points) \n",
    "exam_score = np.round(exam_score)\n",
    "exam_score[exam_score > 3000] = 3000\n",
    "exam_score[exam_score < 0] = 0\n",
    "\n",
    "# Generiraj podatke o ocjenama iz srednje škole koristeći normalnu razdiobu i ograniči ih na interval [1, 5].\n",
    "grade_in_highschool = np.random.normal(loc=3, scale = 2.0, size = n_data_points)\n",
    "grade_in_highschool[grade_in_highschool > 5] = 5\n",
    "grade_in_highschool[grade_in_highschool < 1] = 1\n",
    "\n",
    "# Matrica dizajna.\n",
    "grades_X = np.array([exam_score,grade_in_highschool]).T\n",
    "\n",
    "# Završno, generiraj izlazne vrijednosti.\n",
    "rand_noise = np.random.normal(loc=0.0, scale = 0.5, size = n_data_points)\n",
    "exam_influence = 0.9\n",
    "grades_y = ((exam_score / 3000.0) * (exam_influence) + (grade_in_highschool / 5.0) \\\n",
    "            * (1.0 - exam_influence)) * 5.0 + rand_noise\n",
    "grades_y[grades_y < 1] = 1\n",
    "grades_y[grades_y > 5] = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Iscrtajte ovisnost ciljne vrijednosti (y-os) o prvoj i o drugoj značajki (x-os). Iscrtajte dva odvojena grafa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Vaš kôd ovdje"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Naučite model L2-regularizirane regresije ($\\lambda = 0.01$), na podacima `grades_X` i `grades_y`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Vaš kôd ovdje"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sada ponovite gornji eksperiment, ali prvo skalirajte podatke `grades_X` i `grades_y` i spremite ih u varijable `grades_X_fixed` i `grades_y_fixed`. Za tu svrhu, koristite [`StandardScaler`](http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "# Vaš kôd ovdje"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q:** Gledajući grafikone iz podzadatka (a), koja značajka bi trebala imati veću magnitudu, odnosno važnost pri predikciji prosjeka na studiju? Odgovaraju li težine Vašoj intuiciji? Objasnite.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *7. Multikolinearnost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Izradite skup podataka `grades_X_fixed_colinear` tako što ćete u skupu `grades_X_fixed` iz\n",
    "zadatka *7b* duplicirati zadnji stupac (ocjenu iz srednje škole). Time smo efektivno uveli savršenu multikolinearnost."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Vaš kôd ovdje"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ponovno, naučite na ovom skupu L2-regularizirani model regresije ($\\lambda = 0.01$)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Vaš kôd ovdje"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q:** Usporedite iznose težina s onima koje ste dobili u zadatku *7b*. Što se dogodilo?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Slučajno uzorkujte 50% elemenata iz skupa `grades_X_fixed_colinear` i naučite dva modela L2-regularizirane regresije, jedan s $\\lambda=0.01$ i jedan s $\\lambda=1000$). Ponovite ovaj pokus 10 puta (svaki put s drugim podskupom od 50% elemenata).  Za svaki model, ispišite dobiveni vektor težina u svih 10 ponavljanja te ispišite standardnu devijaciju vrijednosti svake od težina (ukupno šest standardnih devijacija, svaka dobivena nad 10 vrijednosti)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Vaš kôd ovdje"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q:** Kako regularizacija utječe na stabilnost težina?  \n",
    "**Q:** Jesu li koeficijenti jednakih magnituda kao u prethodnom pokusu? Objasnite zašto."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
